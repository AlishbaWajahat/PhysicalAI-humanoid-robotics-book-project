---
id: 0001
title: Create RAG Chatbot Backend Spec
stage: spec
date: 2025-12-10
surface: agent
model: claude-sonnet-4-5-20250929
feature: 005-rag-chatbot-backend
branch: 005-rag-chatbot
user: AlishbaWajahat
command: /sp.specify
labels: ["spec", "rag-chatbot", "backend", "requirements"]
links:
  spec: "../specs/005-rag-chatbot-backend/spec.md"
  ticket: null
  adr: null
  pr: null
files:
 - specs/005-rag-chatbot-backend/spec.md
 - specs/005-rag-chatbot-backend/checklists/requirements.md
tests:
 - none
---

## Prompt

Write a full spec.md for my backend project with the following requirements:

ğŸ¯ Project Goal

Build the backend of an Integrated RAG Chatbot that answers user questions only from my book's content.
The system will:

Extract book content from the docs/ folder

Chunk â†’ embed â†’ store into Qdrant vector database

Build an agent that retrieves the most relevant chunks and generates responses

Support questions about the book, selected text, and metadata (parts, chapters, summaries)

Use openai-agents SDK for the backend

Frontend later will be built with chatkit-js, backend uses chatkit-python, so no FastAPI is needed.

ğŸ§± Tech Stack

Backend: openai-agents SDK

Vector DB: Qdrant

Embedding model: Cohere

LLM model: Gemini model (via OpenAI Chat Completions API â†’ use best free Gemini model)

Context7 MCP server: must be used to fetch latest documentation when needed

Environment: load all secrets from .env

No OOP â€” use simple, clean, functional code

ğŸ“¦ Data Workflow Requirements

Include detailed steps for:

Extracting book text from docs/

Chunking text

Creating embeddings using Cohere embeddings

Storing vectors in Qdrant

Supporting incremental indexing for future new book files

Querying Qdrant to retrieve top 5 most relevant chunks

Passing retrieved chunks into the agent for answering

ğŸ¤– Agent Requirements

Specify that the agent must:

Use Gemini model via OpenAI

Use a retrieve tool built around Qdrant search

Be strictly instructed to answer only from book content

Provide short, concise answers by default, unless user asks for details

Be beginner-friendly and helpful

Be able to answer:

factual questions from the book

search queries

metadata questions (parts list, chapters, chapter count, URLs, summaries)

ğŸ“˜ Additional Constraints

Code must be simple, readable, and breathable

Avoid OOP entirely

Use context7 MCP server to fetch latest docs instead of relying on internal knowledge

Ask clarifying questions whenever something is missing

âœï¸ What the output should be

Ge

## Response snapshot

Created a comprehensive specification for the RAG Chatbot Backend, including user scenarios, functional requirements, success criteria, and a quality checklist.

## Outcome

- âœ… Impact: Created complete feature specification for RAG chatbot backend with user stories, requirements, and success metrics
- ğŸ§ª Tests: none
- ğŸ“ Files: specs/005-rag-chatbot-backend/spec.md, specs/005-rag-chatbot-backend/checklists/requirements.md
- ğŸ” Next prompts: /sp.plan to create implementation plan, /sp.tasks to break down implementation tasks
- ğŸ§  Reflection: The specification captures all the essential requirements for the RAG chatbot backend while maintaining focus on user value and business needs.

## Evaluation notes (flywheel)

- Failure modes observed: None
- Graders run and results (PASS/FAIL): N/A
- Prompt variant (if applicable): N/A
- Next experiment (smallest change to try): N/A
